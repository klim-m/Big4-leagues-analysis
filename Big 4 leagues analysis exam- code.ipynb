{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb606909-7272-43a7-a2df-c13fc6a713e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import regex as re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5e5eb5-513e-4eda-9132-57042d6e6d4a",
   "metadata": {},
   "source": [
    "# Correlation between population of city and Win/loss ratio n NHL 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f0babaec-41ff-4427-abfc-8425c5a7d839",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mendo\\AppData\\Local\\Temp/ipykernel_15492/2550715962.py:15: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  nhl_df[\"team\"] = nhl_df[\"team\"].str.replace(\"*\", \"\")  #removes all the asterisks from team names\n",
      "C:\\Users\\mendo\\AppData\\Local\\Temp/ipykernel_15492/2550715962.py:20: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  cities[\"NHL\"] = cities[\"NHL\"].str.replace(r\"\\[.+\\]\", \"\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.012485959345532899"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cities=pd.read_html(\"Datasets/wikipedia_data.html\")[1]    #returns 1st table from wiki page\n",
    "cities=cities.iloc[:-1,[0,3,5,6,7,8]]       #all rows except last for mentioned column numbers\n",
    "cities\n",
    "nhl_df = pd.read_csv(\"Datasets/nhl.csv\")\n",
    "nhl_df\n",
    "\n",
    "def clean_nhl_df():\n",
    "    cities=pd.read_html(\"Datasets/wikipedia_data.html\")[1]    \n",
    "    cities=cities.iloc[:-1,[0,3,5,6,7,8]]       \n",
    "    nhl_df = pd.read_csv(\"Datasets/nhl.csv\")\n",
    "    \n",
    "    #Cleaning NHL DF\n",
    "    nhl_df = nhl_df[nhl_df[\"year\"] ==2018]    #only retunrs data with 2018 \n",
    "    nhl_df[\"team\"] = nhl_df[\"team\"].str.replace(\"*\", \"\")  #removes all the asterisks from team names\n",
    "    nhl_df[\"team\"]= nhl_df[\"team\"].apply(lambda x: x.split(\" \")[-1])   #splits team names and keeps last word of team \n",
    "    \n",
    "    \n",
    "    #clean NHL row column in cities df\n",
    "    cities[\"NHL\"] = cities[\"NHL\"].str.replace(r\"\\[.+\\]\", \"\")\n",
    "    cities[\"NHL\"] = cities[\"NHL\"].replace({\"RangersIslandersDevils\": \"Rangers,Islanders,Devils\",\n",
    "                                           \"KingsDucks\" : \"Kings,Ducks\",\n",
    "                                           \"Red Wings\": \"Red,Wings\",\n",
    "                                           \"Maple Leafs\": \"Maple,Leafs\",\n",
    "                                           \"Blue Jackets\": \"Blue,Jackets\",\n",
    "                                           \"Golden Knights\": \"Golden,Knights\"})  #splitting teams with spaces into words\n",
    "                                              \n",
    "    cities[\"NHL\"] = cities[\"NHL\"].apply(lambda x: x.split(\",\"))\n",
    "    cities = cities.explode(\"NHL\")    #splits any row in NBA with \",\" into seperate row \n",
    "    \n",
    "    #merge both dfs based on team name \n",
    "    merged_df = pd.merge(cities, nhl_df, left_on= \"NHL\", right_on= \"team\")   #merging based on columns with team names\n",
    "    merged_df= merged_df.iloc[:,[0,1,5,6,8,9]] #filtering only necessary columns\n",
    "    merged_df[\"W-L%\"] = merged_df[\"W\"].astype(\"float\") / (merged_df[\"W\"].astype(\"float\") + merged_df[\"L\"].astype(\"float\"))  #creating calculated column with W-L ratio \n",
    "    merged_df[\"Population (2016 est.)[8]\"] =    merged_df[\"Population (2016 est.)[8]\"].astype(\"float\")    #converting population column to float \n",
    "    \n",
    "    \n",
    "    #Reassigning values for duplicate areas (i.e NY, LS)\n",
    "    merged_df.loc[merged_df[\"Metropolitan area\"] == \"New York City\", \"W-L%\"] = 0.5182013333333334   #assigns mean of 3 W-L% for NY\n",
    "    merged_df.loc[merged_df[\"Metropolitan area\"] == \"Los Angeles\", \"W-L%\"] = 0.6228945 #assigns mean of 3 W-L% for NY\n",
    "    merged_df = merged_df.drop_duplicates(subset= \"Metropolitan area\")\n",
    "    merged_df = merged_df.reset_index()   #creates another ordered index\n",
    "    merged_df = merged_df.drop(columns=\"index\")   #removes original filtered index column \n",
    "    return merged_df\n",
    "\n",
    "def nhl_correlation():\n",
    "    corr_df= clean_nhl_df()\n",
    "    \n",
    "    population_by_region = corr_df[\"Population (2016 est.)[8]\"]   #creates column for comparison\n",
    "    win_loss_by_region = corr_df[\"W-L%\"]         #creates w-l column for comparison\n",
    "    \n",
    "    #correlation = stats.pearsonr(corr_df[\"Population (2016 est.)[8]\"], corr_df[\"W-L%\"])  #Direct method\n",
    "    #correlation = correlation[0]   #only keeps corr value which is 0.012\n",
    "    \n",
    "    result = stats.pearsonr(population_by_region, win_loss_by_region)\n",
    "    return result[0]\n",
    "\n",
    "clean_nhl_df() \n",
    "nhl_correlation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de4205e-796f-4691-a0c4-dfc97e3920f4",
   "metadata": {},
   "source": [
    "# Correlation between population of city and Win/loss ratio in NBA 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7f7fe769-baa1-4836-8cf9-98700424c9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mendo\\AppData\\Local\\Temp/ipykernel_15492/3301255494.py:17: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  cities[\"NBA\"] = cities[\"NBA\"].str.replace(r\"\\[.+\\]\", \"\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.1763635064218294"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def clean_nba_df():\n",
    "    nba_df=pd.read_csv(\"Datasets/nba.csv\")\n",
    "    cities=pd.read_html(\"Datasets/wikipedia_data.html\")[1]\n",
    "    cities=cities.iloc[:-1,[0,3,5,6,7,8]]\n",
    "    \n",
    "    #cleaning nba_df\n",
    "    nba_df  = nba_df[nba_df[\"year\"] == 2018]\n",
    "    #nba_df[\"team\"]= nba_df[\"team\"].str.replace(r\"\\*.+\", \"\")\n",
    "    #nba_df[\"team\"]= nba_df[\"team\"].str.replace(r\"\\(.+\\)\", \"\")\n",
    "    nba_df[\"team\"] = nba_df[\"team\"].apply(lambda x: re.sub(r\"(\\*)*\\s\\(\\d+\\)\", \"\", x))\n",
    "    nba_df[\"team\"]= nba_df[\"team\"].apply(lambda x: x.split(\" \")[-1])\n",
    "    #might need to another split line \n",
    "    \n",
    "    #cleaning wikipedia_df\n",
    "    cities[\"NBA\"] = cities[\"NBA\"].str.replace(r\"\\[.+\\]\", \"\")\n",
    "    cities[\"NBA\"] = cities[\"NBA\"].replace({\"KnicksNets\": \"Knicks,Nets\",\n",
    "                                        \"LakersClippers\": \"Lakers,Clippers\",\n",
    "                                          \"Trail Blazers\": \"Blazers\"})\n",
    "    \n",
    "    cities[\"NBA\"] = cities[\"NBA\"].apply(lambda x: x.split(\",\"))                               \n",
    "    cities = cities.explode(\"NBA\")   #splits any row in NBA with \",\" into seperate row \n",
    "    \n",
    "    #merging both dfs\n",
    "    merged_df = pd.merge(cities, nba_df, left_on= \"NBA\", right_on = \"team\")\n",
    "    merged_df= merged_df.iloc[:, [0,1,4,6,9]]\n",
    "    merged_df[\"W/L%\"] = merged_df[\"W/L%\"].astype(\"float\")\n",
    "    merged_df[\"Population (2016 est.)[8]\"] = merged_df[\"Population (2016 est.)[8]\"].astype(\"float\")\n",
    "    \n",
    "    #reassigning mean ratio to NY and LS\n",
    "    merged_df.loc[merged_df[\"Metropolitan area\"] == \"New York City\", \"W/L%\"] = 0.3475\n",
    "    merged_df.loc[merged_df[\"Metropolitan area\"] == \"Los Angeles\", \"W/L%\"] = 0.4695\n",
    "    merged_df = merged_df.drop_duplicates(subset= \"Metropolitan area\")\n",
    "    merged_df = merged_df.reset_index()\n",
    "    merged_df = merged_df.drop(columns = \"index\")\n",
    "    return merged_df\n",
    "\n",
    "def nba_correlation():\n",
    "    merged_df = clean_nba_df()\n",
    "    population_by_region = merged_df[\"Population (2016 est.)[8]\"] \n",
    "    win_loss_by_region = merged_df[\"W/L%\"]\n",
    "    \n",
    "    \n",
    "    correlation = stats.pearsonr(population_by_region, win_loss_by_region)\n",
    "    assert len(population_by_region) == len(win_loss_by_region), \"Q2: Your lists must be the same length\"\n",
    "    assert len(population_by_region) == 28, \"Q2: There should be 28 teams being analysed for NBA\"\n",
    "\n",
    "    \n",
    "    return correlation[0]\n",
    "clean_nba_df()\n",
    "nba_correlation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f64ff65-68c1-42b3-8726-97e21716821c",
   "metadata": {},
   "source": [
    "# Correlation between population of city and Win/loss ratio in MLB 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "359ba7f7-dfb5-45c9-9823-99b9743f3762",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mendo\\AppData\\Local\\Temp/ipykernel_16556/3047986418.py:15: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  cities[\"MLB\"] = cities[\"MLB\"].str.replace(r\"\\[.+\\]\", \"\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.16975755699575962"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mlb_df=pd.read_csv(\"Datasets/mlb.csv\")\n",
    "cities=pd.read_html(\"Datasets/wikipedia_data.html\")[1]\n",
    "cities=cities.iloc[:-1,[0,3,5,6,7,8]]\n",
    "\n",
    "def clean_mlb_df():\n",
    "    mlb_df=pd.read_csv(\"Datasets/mlb.csv\")\n",
    "    cities=pd.read_html(\"Datasets/wikipedia_data.html\")[1]\n",
    "    cities=cities.iloc[:-1,[0,3,5,6,7,8]]\n",
    "    \n",
    "    #cleaning mlb df\n",
    "    mlb_df = mlb_df[mlb_df[\"year\"] == 2018]\n",
    "    mlb_df[\"team\"] = mlb_df[\"team\"].apply(lambda x: x.split(\" \")[-1])\n",
    "    \n",
    "    #cleaning cities_df\n",
    "    cities[\"MLB\"] = cities[\"MLB\"].str.replace(r\"\\[.+\\]\", \"\") \n",
    "    cities[\"MLB\"] = cities[\"MLB\"].replace({\"Blue Jays\": \"Blue,Jays\", \n",
    "                                           \"CubsWhite Sox\": \"Cubs,White,Sox\", \n",
    "                                           \"DodgersAngels\": \"Dodgers,Angels\", \n",
    "                                           \"GiantsAthletics\": \"Giants,Athletics\", \n",
    "                                           \"YankeesMets\": \"Yankees,Mets\",\n",
    "                                           \"Red Sox\": \"Red,Sox\"})\n",
    "    cities[\"MLB\"] =cities[\"MLB\"].apply(lambda x: x.split(\",\"))\n",
    "    cities = cities.explode(\"MLB\")\n",
    "    \n",
    "    #merging dfs\n",
    "    merged_df = pd.merge(cities, mlb_df, left_on = \"MLB\", right_on= \"team\")\n",
    "    merged_df = merged_df[[\"Metropolitan area\", \"Population (2016 est.)[8]\", \"MLB\", \"team\", \"W-L%\"]]\n",
    "    merged_df[\"Population (2016 est.)[8]\"] = merged_df[\"Population (2016 est.)[8]\"].astype(\"float\")\n",
    "    merged_df[\"W-L%\"] = merged_df[\"W-L%\"].astype(\"float\")\n",
    "    \n",
    "    #reassinging mean \n",
    "    merged_df.loc[merged_df[\"Metropolitan area\"] == \"New York City\", \"W-L%\"] = 0.546\n",
    "    merged_df.loc[merged_df[\"Metropolitan area\"] == \"Los Angeles\", \"W-L%\"] = 0.529\n",
    "    merged_df.loc[merged_df[\"Metropolitan area\"] == \"San Francisco Bay Area\", \"W-L%\"] = 0.525\n",
    "    merged_df.loc[merged_df[\"Metropolitan area\"] == \"Chicago\", \"W-L%\"] = 0.54433333\n",
    "    merged_df.loc[merged_df[\"Metropolitan area\"] == \"Chicago\", \"W-L%\"] = 0.525\n",
    "    \n",
    "    #Dropping indices\n",
    "    merged_df = merged_df.drop_duplicates(subset= \"Metropolitan area\")\n",
    "    merged_df = merged_df.reset_index()\n",
    "    merged_df = merged_df.drop(columns = \"index\")\n",
    "    return merged_df\n",
    "\n",
    "def mlb_correlation(): \n",
    "    merged_df = clean_mlb_df()\n",
    "    \n",
    "    population_by_region = merged_df[\"Population (2016 est.)[8]\"] # pass in metropolitan area population from cities\n",
    "    win_loss_by_region = merged_df[\"W-L%\"] # pass in win/loss ratio from mlb_df in the same order as cities[\"Metropolitan area\"]\n",
    "\n",
    "    correlation = stats.pearsonr(population_by_region, win_loss_by_region)\n",
    "    \n",
    "    return correlation [0]\n",
    "clean_mlb_df()\n",
    "mlb_correlation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f302f349-b43c-4e35-a221-abed52f4e421",
   "metadata": {},
   "source": [
    "# Correlation between population of city and Win/loss ratio in NFL 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75fef899-8933-4dfe-bc93-dcd4b41a0b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mendo\\AppData\\Local\\Temp/ipykernel_16556/4214798702.py:14: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  nfl_df[\"team\"] = nfl_df[\"team\"].str.replace(r\"[\\+]|[\\*]\", \"\")\n",
      "C:\\Users\\mendo\\AppData\\Local\\Temp/ipykernel_16556/4214798702.py:18: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  cities[\"NFL\"] = cities[\"NFL\"].str.replace(r\"\\[.+\\]\", \"\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.004282141436393008"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nfl_df=pd.read_csv(\"Datasets/nfl.csv\")\n",
    "cities=pd.read_html(\"Datasets/wikipedia_data.html\")[1]\n",
    "cities=cities.iloc[:-1,[0,3,5,6,7,8]]\n",
    "\n",
    "def clean_nfl_df():\n",
    "    nfl_df=pd.read_csv(\"Datasets/nfl.csv\")\n",
    "    cities=pd.read_html(\"Datasets/wikipedia_data.html\")[1]\n",
    "    cities=cities.iloc[:-1,[0,3,5,6,7,8]]\n",
    "    \n",
    "    #cleaning NFL\n",
    "    nfl_df = nfl_df[nfl_df[\"year\"] == 2018]\n",
    "    nfl_df[\"team\"] = nfl_df[\"team\"].str.replace(r\"[\\+]|[\\*]\", \"\")\n",
    "    nfl_df[\"team\"] = nfl_df[\"team\"].apply(lambda x: x.split(\" \")[-1])\n",
    "    \n",
    "    #cleaning cities df\n",
    "    cities[\"NFL\"] = cities[\"NFL\"].str.replace(r\"\\[.+\\]\", \"\")\n",
    "    cities[\"NFL\"] = cities[\"NFL\"].replace({\"GiantsJets\":\"Giants,Jets\",\n",
    "                                          \"RamsChargers\": \"Rams,Chargers\",\n",
    "                                          \"49ersRaiders\": \"49ers,Raiders\"})\n",
    "    cities[\"NFL\"] = cities[\"NFL\"].apply(lambda x: x.split(\",\"))\n",
    "    cities= cities.explode(\"NFL\")\n",
    "   \n",
    "    #merging df\n",
    "    merged_df = pd.merge(cities, nfl_df, left_on= \"NFL\", right_on= \"team\")\n",
    "    merged_df = merged_df[['Metropolitan area', 'Population (2016 est.)[8]', 'NFL', 'W-L%', 'team']]\n",
    "    \n",
    "    #changing types \n",
    "    merged_df[\"Population (2016 est.)[8]\"] = merged_df[\"Population (2016 est.)[8]\"].astype(\"float\")\n",
    "    merged_df[\"W-L%\"] = merged_df[\"W-L%\"].astype(\"float\")\n",
    "    \n",
    "    #Reassigning means \n",
    "    merged_df.loc[merged_df[\"Metropolitan area\"] == \"New York City\", \"W-L%\"] = 0.2815\n",
    "    merged_df.loc[merged_df[\"Metropolitan area\"] == \"Los Angeles\", \"W-L%\"] = 0.7815\n",
    "    merged_df.loc[merged_df[\"Metropolitan area\"] == \"San Francisco Bay Area\" ,\"W-L%\"] = 0.250\n",
    "    \n",
    "    #dropping duplicates\n",
    "    merged_df = merged_df.drop_duplicates(subset = \"Metropolitan area\")\n",
    "    merged_df = merged_df.reset_index()\n",
    "    merged_df = merged_df.drop(columns= \"index\")\n",
    "    \n",
    "    #dropping duplicates\n",
    "    return merged_df\n",
    "\n",
    "\n",
    "def nfl_correlation(): \n",
    "    # YOUR CODE HERE\n",
    "    merged_df = clean_nfl_df()\n",
    "    \n",
    "    population_by_region = merged_df[\"Population (2016 est.)[8]\"] \n",
    "    win_loss_by_region = merged_df[\"W-L%\"]\n",
    "    \n",
    "    correlation = stats.pearsonr(population_by_region, win_loss_by_region)\n",
    "    return correlation[0]\n",
    "    \n",
    "clean_nfl_df()\n",
    "nfl_correlation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ee7664-2662-48a9-a491-3d88db8091d0",
   "metadata": {},
   "source": [
    "# Hypothesis test- \"given that an area has two sports teams in different sports, those teams will perform the same within their respective sports\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "38c54a01-4e5a-4c90-9199-54ff9f723b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb_df=pd.read_csv(\"Datasets/mlb.csv\")\n",
    "nhl_df=pd.read_csv(\"Datasets/nhl.csv\")\n",
    "nba_df=pd.read_csv(\"Datasets/nba.csv\")\n",
    "nfl_df=pd.read_csv(\"Datasets/nfl.csv\")\n",
    "cities=pd.read_html(\"Datasets/wikipedia_data.html\")[1]\n",
    "cities=cities.iloc[:-1,[0,3,5,6,7,8]]\n",
    "\n",
    "def clean_dfs():\n",
    "    mlb_df = clean_mlb_df()\n",
    "    nhl_df= clean_nhl_df()\n",
    "    nfl_df = clean_nfl_df()\n",
    "    nba_df = clean_nba_df()\n",
    "\n",
    "    mlb_df = mlb_df[[\"Metropolitan area\", \"W-L%\"]]\n",
    "    nhl_df = nhl_df[[\"Metropolitan area\", \"W-L%\"]]\n",
    "    nfl_df = nfl_df[[\"Metropolitan area\", \"W-L%\"]]\n",
    "    nba_df = nba_df[[\"Metropolitan area\", \"W/L%\"]]\n",
    "    nba_df = nba_df.rename(columns = {\"W/L%\" : \"W-L%\"})\n",
    "    \n",
    "    return (mlb_df, nhl_df, nfl_df, nba_df)\n",
    "\n",
    "#clean_dfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2ccc0db4-9437-40c0-88d5-91cd0f97c630",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mendo\\AppData\\Local\\Temp/ipykernel_15492/3445863027.py:14: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  nfl_df[\"team\"] = nfl_df[\"team\"].str.replace(r\"[\\+]|[\\*]\", \"\")\n",
      "C:\\Users\\mendo\\AppData\\Local\\Temp/ipykernel_15492/3445863027.py:18: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  cities[\"NFL\"] = cities[\"NFL\"].str.replace(r\"\\[.+\\]\", \"\")\n",
      "C:\\Users\\mendo\\AppData\\Local\\Temp/ipykernel_15492/3301255494.py:17: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  cities[\"NBA\"] = cities[\"NBA\"].str.replace(r\"\\[.+\\]\", \"\")\n",
      "C:\\Users\\mendo\\AppData\\Local\\Temp/ipykernel_15492/2550715962.py:15: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  nhl_df[\"team\"] = nhl_df[\"team\"].str.replace(\"*\", \"\")  #removes all the asterisks from team names\n",
      "C:\\Users\\mendo\\AppData\\Local\\Temp/ipykernel_15492/2550715962.py:20: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  cities[\"NHL\"] = cities[\"NHL\"].str.replace(r\"\\[.+\\]\", \"\")\n",
      "C:\\Users\\mendo\\AppData\\Local\\Temp/ipykernel_15492/1798709794.py:16: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  cities[\"MLB\"] = cities[\"MLB\"].str.replace(r\"\\[.+\\]\", \"\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NFL</th>\n",
       "      <th>NBA</th>\n",
       "      <th>NHL</th>\n",
       "      <th>MLB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NFL</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.937509</td>\n",
       "      <td>0.030318</td>\n",
       "      <td>0.835932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NBA</th>\n",
       "      <td>0.937509</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.022386</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NHL</th>\n",
       "      <td>0.030318</td>\n",
       "      <td>0.022386</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLB</th>\n",
       "      <td>0.835932</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001336</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          NFL       NBA       NHL       MLB\n",
       "NFL       NaN  0.937509  0.030318  0.835932\n",
       "NBA  0.937509       NaN  0.022386  1.000000\n",
       "NHL  0.030318  0.022386       NaN  0.001336\n",
       "MLB  0.835932  1.000000  0.001336       NaN"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_p_vals(leagues):\n",
    "    p_vals = pd.DataFrame(columns=leagues.keys(), index=leagues.keys())   #creates empty df with keys of the league names passed i.e NHL, NFL etc\n",
    "    for (league_name1, league_df1) in leagues.items():           #parses through name and entire df1 of first in league\n",
    "        for (league_name2, league_df2) in leagues.items():       #parses through same in another df\n",
    "            merged_league = pd.merge(league_df1, league_df2, on=\"Metropolitan area\")  #merges both on area name \n",
    "            p_vals.loc[league_name1, league_name2] = stats.ttest_rel(merged_league[\"W-L%_x\"], merged_league[\"W-L%_y\"])[1]    #sets value of merged with results of related ttest of both dfs wi/loss ratio\n",
    "            \n",
    "    return p_vals\n",
    "\n",
    "def sports_team_performance():\n",
    "    # YOUR CODE HERE\n",
    "#     raise NotImplementedError()\n",
    "    (nfl_df, nba_df, nhl_df, mlb_df) = clean_dfs()\n",
    "    \n",
    "    leagues = {\"NFL\": nfl_df, \"NBA\": nba_df, \"NHL\": nhl_df, \"MLB\": mlb_df}\n",
    "    p_vals_dict = calculate_p_vals(leagues)\n",
    "    p_vals = pd.DataFrame(p_vals_dict).astype(\"float\")\n",
    "    return p_vals\n",
    "\n",
    "sports_team_performance()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509d0da9-ce76-4453-9098-f0ed3f52c1fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49c973c-65dd-4c83-86bc-860218d9455c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaf5c6e-f85d-4353-a002-49e41989279e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
